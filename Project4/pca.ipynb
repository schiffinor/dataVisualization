{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**YOUR NAME HERE**\n",
    "\n",
    "Spring 2024\n",
    "\n",
    "CS 251 / 252: Data Analysis and Visualization\n",
    "\n",
    "Project 4: Principal Component Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "plt.style.use(['seaborn-v0_8-colorblind', 'seaborn-v0_8-darkgrid'])\n",
    "plt.rcParams.update({'font.size': 20})\n",
    "\n",
    "np.set_printoptions(suppress=True, precision=5)\n",
    "\n",
    "# Automatically reload external modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Principal component analysis\n",
    "\n",
    "In this task, you will implement principal component analysis (PCA) to reduce the dimensionality of data while maximizing the information that is preserved. You will use the mystery dataset to test your code and ultimately compare how PCA reduces the dimensionality from 3D to 2D with your manual rotation and projection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import pca"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2a. Import mystery dataset\n",
    "\n",
    "In the below cell:\n",
    "- load in the mystery dataset (`mystery.csv`) into a pandas DataFrame called `mys_data`.\n",
    "- select the `x`, `y`, and `z` variables (drop the `color` variable).\n",
    "- print out the head (only showing the first 5 data samples).\n",
    "- create an `PCA` object called `mys_pca` based on the DataFrame that you just created.\n",
    "\n",
    "Your code should print something that looks like this:\n",
    "```\n",
    "          x           y           z\n",
    "0  6.183216   86.707892   90.551566\n",
    "1  0.969658   16.972285  137.976605\n",
    "2  0.727076   57.112193  139.795502\n",
    "3  8.433828   30.348513  113.600202\n",
    "4  8.188306  133.978413  120.671505\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2b. Implement PCA\n",
    "\n",
    "Implement and test the following methods necessary to perform PCA in `pca.py`.\n",
    "\n",
    "- `covariance_matrix`: Computes the covariance matrix of data\n",
    "- `compute_prop_var`: Computes the proportion variance accounted for by the principal components (PCs).\n",
    "- `compute_cum_var`: Computes the *cumulative* proportion variance accounted for by the PCs.\n",
    "- `fit`: Method to compute the PCs of the dataset (e.g. eigenvectors, eigenvalues).\n",
    "- `elbow_plot`: Plots the cumulative variance accounted for with different numbers of PCS.\n",
    "- `pca_project`: Project the data into PCA space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (i) Test `covariance_matrix`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Test covariance here\n",
    "np.random.seed(0)\n",
    "d = np.random.randn(100, 3)\n",
    "cov_mat = mys_pca.covariance_matrix(d)\n",
    "print(f'Your covariance matrix has shape {cov_mat.shape} and should be (3, 3)')\n",
    "print(f'Your covariance matrix is:\\n{cov_mat} and should be\\n[[ 1.06338 -0.07562  0.11267]\\n [-0.07562  0.97412 -0.0222 ]\\n [ 0.11267 -0.0222   0.96217]]')"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (ii) Test `prop_var`\n",
    "\n",
    "Takes eigenvalues ordered large-to-small and computes the proportion of the total variance account for by the $k^{th}$ principal component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Test prop_var here\n",
    "np.random.seed(0)\n",
    "test_evals = np.sort(np.random.uniform(size=(10,)))[::-1]\n",
    "prop_var = mys_pca.compute_prop_var(test_evals)\n",
    "print(f'Your list is actually a Python list (as it should be)? {isinstance(prop_var, list)}')\n",
    "print(f'Your proportion variance list length is {len(prop_var)} and should be 10')\n",
    "print(f'Your proportion variance list begins with\\n{prop_var[:2]} and it should be\\n[0.15649813681155653, 0.1448232917174111]')"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (iii) Test `compute_cum_var`\n",
    "\n",
    "Takes proportion variance for principal components, ordered large-to-small, and computes the cumulative sum (cumulative variance accounted for by the first $k$ principal components)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Test accum_var here\n",
    "np.random.seed(0)\n",
    "test_evals = np.sort(np.random.uniform(size=(10,)))[::-1]\n",
    "prop_var = mys_pca.compute_prop_var(test_evals)\n",
    "accum_var = mys_pca.compute_cum_var(prop_var)\n",
    "print(f'Your list is actually a Python list (as it should be)? {isinstance(accum_var, list)}')\n",
    "print(f'Your cumulative variance list length is {len(accum_var)} and should be 10')\n",
    "print(f'Your cumulative variance list begins with\\n{accum_var[:2]} and should be\\n[0.15649813681155653, 0.3013214285289676]')"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (iv) Test `fit`\n",
    "\n",
    "Performs PCA using the covariance matrix method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Test pca (no normalization) here\n",
    "mys_headers = list(mys_data.columns)\n",
    "mys_pca.fit(mys_headers)\n",
    "\n",
    "# test that instance variable shape are correct\n",
    "print(f'There are {len(mys_pca.vars)} vars in Mystery PCA and there should be 3.')\n",
    "print(f'The original PCA data has shape {mys_pca.A.shape} and should be (2000, 3).')\n",
    "print(f'Eigenvector shape: {mys_pca.e_vecs.shape} should be (3, 3).\\nEigenvalue shape: {mys_pca.e_vals.shape} should be (3,).')\n",
    "print(f'Length of proportion variance account for: {len(mys_pca.get_prop_var())} should be 3.')\n",
    "print(f'Length of cumulative proportion variance account for: {len(mys_pca.get_cum_var())} should be 3.')\n",
    "print()\n",
    "\n",
    "# Test values\n",
    "print(f\"Your vars in Mystery PCA:\\n{mys_pca.vars}  and they should be\\n['x', 'y', 'z']\")\n",
    "print(f'Your eigenvectors:\\n{mys_pca.e_vecs}. They should be\\n[[ 0.0048  -0.00307  0.99998]\\n [ 0.00747 -0.99997 -0.00311]\\n [ 0.99996  0.00749 -0.00478]].')\n",
    "print(f'Your eigenvalues:\\n{mys_pca.e_vals}. They should be\\n[4922.17303  975.37206   10.95308]')\n",
    "print(f'Cumulative proportion variance account for:\\n{mys_pca.get_cum_var()}. It should be\\n[0.8330666933541857, 0.9981462157185522, 1.0].')\n",
    "\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Test pca (normalization) here\n",
    "mys_headers = list(mys_data.columns)\n",
    "mys_pca.fit(mys_headers, normalize_dataset=True)\n",
    "\n",
    "# test that instance variable shape are correct\n",
    "print(f'There are {len(mys_pca.vars)} vars in Mystery PCA and there should be 3.')\n",
    "print(f'The original PCA data has shape {mys_pca.A.shape} and should be (2000, 3).')\n",
    "print(f'Eigenvector shape: {mys_pca.e_vecs.shape} should be (3, 3).\\nEigenvalue shape: {mys_pca.e_vals.shape} should be (3,).')\n",
    "print(f'Length of proportion variance account for: {len(mys_pca.get_prop_var())} should be 3.')\n",
    "print(f'Length of cumulative proportion variance account for: {len(mys_pca.get_cum_var())} should be 3.')\n",
    "print(f'Data min/max is {mys_pca.A.min()}/{mys_pca.A.max()} should be 0.0/1.0')\n",
    "print()\n",
    "\n",
    "# Test values\n",
    "print(f'Your eigenvalues:\\n{mys_pca.e_vals}. They should be\\n[0.07135 0.05681 0.04928]')\n",
    "print(f'Cumulative proportion variance account for:\\n{mys_pca.get_cum_var()}. It should be\\n[0.402116890496464, 0.7222698215107564, 1.0].')\n",
    "\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (v) Test `elbow_plot`\n",
    "\n",
    "Visualize the cumulative proportion variance accounted for by the first $k$ principal components.\n",
    "\n",
    "**Make sure that you have the normalized PCA in memory before proceeding (the last cell of test code above)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# test elbow plot\n",
    "mys_pca.elbow_plot()\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (vi) Test `pca_project`\n",
    "\n",
    "Project the data onto a list of the top $2$ principal components (`pcs_to_keep = [0, 1]`) then make a 2D scatter plot showing your PCA projected data. Label the x and y axes appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "num_dims = 2\n",
    "pcs_to_keep = np.arange(num_dims)\n",
    "mys_proj = mys_pca.pca_project(pcs_to_keep)\n",
    "\n",
    "plt.plot(mys_proj[:, 0], mys_proj[:, 1], 'o' )\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2c. Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 6:** Based on the Mystery elbow plot (Task 2b (v)), how many principal components would you drop and **why?**\n",
    "\n",
    "**Question 7:** How does the the PCA projected version of the mystery dataset compare to the projection that you achieved onto the `x`-`y` plane after rotating the dataset? **Why is there this similarity or difference in the results?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer 6:** \n",
    "\n",
    "**Answer 7:** "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
